{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Álvaro\\anaconda3.1\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Álvaro\\Final-project\\Data\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventTime_ay</th>\n",
       "      <th>Date</th>\n",
       "      <th>email</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>Sub_Categoria</th>\n",
       "      <th>campaign</th>\n",
       "      <th>medium</th>\n",
       "      <th>userId</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>time_diff_ay_ac</th>\n",
       "      <th>time_diff_ac_vg</th>\n",
       "      <th>time_diff_vg_ff</th>\n",
       "      <th>time_diff_ff_fd</th>\n",
       "      <th>time_diff_fd_pm</th>\n",
       "      <th>city</th>\n",
       "      <th>cityId</th>\n",
       "      <th>region</th>\n",
       "      <th>regionId</th>\n",
       "      <th>sessions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-09 10:19:12</td>\n",
       "      <td>2020-05-09</td>\n",
       "      <td>eduardoperez@seincomobiliario.com</td>\n",
       "      <td>EDUARDO</td>\n",
       "      <td>PEREZ</td>\n",
       "      <td>disenador-de-muebles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>083e8b2f-af6a-46b4-a9b9-4f79c1a32cf1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>1005424</td>\n",
       "      <td>Catalonia</td>\n",
       "      <td>20278</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-12 14:50:10</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>alexvonder@hotmail.com</td>\n",
       "      <td>Alexandra</td>\n",
       "      <td>Perez</td>\n",
       "      <td>chofer</td>\n",
       "      <td>01_España_Genéricas</td>\n",
       "      <td>ppc</td>\n",
       "      <td>0feedfe0-5452-434c-8a70-845fa3fd638a</td>\n",
       "      <td>adwords</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>(not set)</td>\n",
       "      <td>Balearic Islands</td>\n",
       "      <td>21387</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-08 18:09:23</td>\n",
       "      <td>2020-11-08</td>\n",
       "      <td>Evo@gmail.com</td>\n",
       "      <td>Juanjo</td>\n",
       "      <td>Akze</td>\n",
       "      <td>fotoperiodista</td>\n",
       "      <td>10430315940</td>\n",
       "      <td>cpc</td>\n",
       "      <td>18bb05eb-d592-4459-a682-f622afb7208c</td>\n",
       "      <td>adwords</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mollet del Valles</td>\n",
       "      <td>1005431</td>\n",
       "      <td>Catalonia</td>\n",
       "      <td>20278</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-25 15:18:38</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>cesardelacalle@grupoccs.es</td>\n",
       "      <td>cesar fernando</td>\n",
       "      <td>de la calle verde</td>\n",
       "      <td>conserje</td>\n",
       "      <td>10430285424</td>\n",
       "      <td>cpc</td>\n",
       "      <td>328d85a1-28b3-493d-ad17-ab58e4567357</td>\n",
       "      <td>adwords</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Villanueva de la Canada</td>\n",
       "      <td>9049240</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>9047045</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-16 11:02:42</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>brsbrs02@gmail.com</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>RS</td>\n",
       "      <td>proyectista</td>\n",
       "      <td>10430285424</td>\n",
       "      <td>cpc</td>\n",
       "      <td>39d91a35-e406-462d-a7a5-7b2291ba8340</td>\n",
       "      <td>adwords</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Coruna</td>\n",
       "      <td>1005479</td>\n",
       "      <td>Galicia</td>\n",
       "      <td>20280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8057</th>\n",
       "      <td>2020-07-05 11:44:34</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>kk@hotmail.com</td>\n",
       "      <td>Santi</td>\n",
       "      <td>Mirlo</td>\n",
       "      <td>entrenador-o-monitor-deportivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7a6ca821-1e99-4156-bb35-9d904828b26b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Castellon de la Plana</td>\n",
       "      <td>1005539</td>\n",
       "      <td>Valencian Community</td>\n",
       "      <td>21388</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>2020-08-29 08:45:46</td>\n",
       "      <td>2020-08-29</td>\n",
       "      <td>sarah@slyne.com</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Slyne</td>\n",
       "      <td>entrenador-o-monitor-deportivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ab772667-56c1-4e2a-b938-ae6e4e3980e3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seville</td>\n",
       "      <td>1005421</td>\n",
       "      <td>Andalusia</td>\n",
       "      <td>20269</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>2020-06-04 09:03:30</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>saraculebras@gmail.com</td>\n",
       "      <td>Sara</td>\n",
       "      <td>Culebras Yagüe</td>\n",
       "      <td>entrenador-o-monitor-deportivo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dc059f05-6e2a-4cb6-9436-826b38d87ce9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Torrejon de Ardoz</td>\n",
       "      <td>1005496</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>9047045</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>2020-09-30 16:03:25</td>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>blancopris@gmail.com</td>\n",
       "      <td>Priscila</td>\n",
       "      <td>Abbona</td>\n",
       "      <td>entrenador-o-monitor-deportivo</td>\n",
       "      <td>RC_pillarpage_nurturing</td>\n",
       "      <td>email</td>\n",
       "      <td>e2af6a50-4e9e-42c0-a5fc-784141160d31</td>\n",
       "      <td>hs_automation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pamplona</td>\n",
       "      <td>1005503</td>\n",
       "      <td>Navarre</td>\n",
       "      <td>9047051</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8061</th>\n",
       "      <td>2020-09-12 07:44:00</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>sharktvdavid@gmail.com</td>\n",
       "      <td>David</td>\n",
       "      <td>Jimenez Ortega</td>\n",
       "      <td>entrenador-o-monitor-deportivo</td>\n",
       "      <td>10430285424</td>\n",
       "      <td>cpc</td>\n",
       "      <td>aa27f98a-4b31-45be-9cb0-f2d5566a978c</td>\n",
       "      <td>adwords</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 days 00:00:08</td>\n",
       "      <td>0 days 00:04:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Palma</td>\n",
       "      <td>1005517</td>\n",
       "      <td>Balearic Islands</td>\n",
       "      <td>20287</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8062 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             eventTime_ay        Date                              email  \\\n",
       "0     2020-05-09 10:19:12  2020-05-09  eduardoperez@seincomobiliario.com   \n",
       "1     2020-04-12 14:50:10  2020-04-12             alexvonder@hotmail.com   \n",
       "2     2020-11-08 18:09:23  2020-11-08                      Evo@gmail.com   \n",
       "3     2020-08-25 15:18:38  2020-08-25         cesardelacalle@grupoccs.es   \n",
       "4     2020-11-16 11:02:42  2020-11-16                 brsbrs02@gmail.com   \n",
       "...                   ...         ...                                ...   \n",
       "8057  2020-07-05 11:44:34  2020-07-05                     kk@hotmail.com   \n",
       "8058  2020-08-29 08:45:46  2020-08-29                    sarah@slyne.com   \n",
       "8059  2020-06-04 09:03:30  2020-06-04             saraculebras@gmail.com   \n",
       "8060  2020-09-30 16:03:25  2020-09-30               blancopris@gmail.com   \n",
       "8061  2020-09-12 07:44:00  2020-09-12             sharktvdavid@gmail.com   \n",
       "\n",
       "           firstName           lastName                   Sub_Categoria  \\\n",
       "0            EDUARDO              PEREZ            disenador-de-muebles   \n",
       "1          Alexandra              Perez                          chofer   \n",
       "2             Juanjo               Akze                  fotoperiodista   \n",
       "3     cesar fernando  de la calle verde                        conserje   \n",
       "4              Bruno                 RS                     proyectista   \n",
       "...              ...                ...                             ...   \n",
       "8057           Santi              Mirlo  entrenador-o-monitor-deportivo   \n",
       "8058           Sarah              Slyne  entrenador-o-monitor-deportivo   \n",
       "8059            Sara     Culebras Yagüe  entrenador-o-monitor-deportivo   \n",
       "8060        Priscila             Abbona  entrenador-o-monitor-deportivo   \n",
       "8061           David     Jimenez Ortega  entrenador-o-monitor-deportivo   \n",
       "\n",
       "                     campaign medium                                userId  \\\n",
       "0                         NaN    NaN  083e8b2f-af6a-46b4-a9b9-4f79c1a32cf1   \n",
       "1         01_España_Genéricas    ppc  0feedfe0-5452-434c-8a70-845fa3fd638a   \n",
       "2                 10430315940    cpc  18bb05eb-d592-4459-a682-f622afb7208c   \n",
       "3                 10430285424    cpc  328d85a1-28b3-493d-ad17-ab58e4567357   \n",
       "4                 10430285424    cpc  39d91a35-e406-462d-a7a5-7b2291ba8340   \n",
       "...                       ...    ...                                   ...   \n",
       "8057                      NaN    NaN  7a6ca821-1e99-4156-bb35-9d904828b26b   \n",
       "8058                      NaN    NaN  ab772667-56c1-4e2a-b938-ae6e4e3980e3   \n",
       "8059                      NaN    NaN  dc059f05-6e2a-4cb6-9436-826b38d87ce9   \n",
       "8060  RC_pillarpage_nurturing  email  e2af6a50-4e9e-42c0-a5fc-784141160d31   \n",
       "8061              10430285424    cpc  aa27f98a-4b31-45be-9cb0-f2d5566a978c   \n",
       "\n",
       "             source  ...  time_diff_ay_ac  time_diff_ac_vg  time_diff_vg_ff  \\\n",
       "0               NaN  ...              NaN              NaN  0 days 00:00:03   \n",
       "1           adwords  ...              NaN              NaN  0 days 00:00:02   \n",
       "2           adwords  ...              NaN              NaN              NaN   \n",
       "3           adwords  ...              NaN              NaN              NaN   \n",
       "4           adwords  ...              NaN              NaN              NaN   \n",
       "...             ...  ...              ...              ...              ...   \n",
       "8057            NaN  ...              NaN              NaN  0 days 00:00:03   \n",
       "8058            NaN  ...              NaN              NaN              NaN   \n",
       "8059            NaN  ...              NaN              NaN  0 days 00:00:03   \n",
       "8060  hs_automation  ...              NaN              NaN  0 days 00:00:04   \n",
       "8061        adwords  ...              NaN              NaN  0 days 00:00:08   \n",
       "\n",
       "      time_diff_ff_fd time_diff_fd_pm                     city     cityId  \\\n",
       "0                 NaN             NaN                Barcelona    1005424   \n",
       "1                 NaN             NaN                (not set)  (not set)   \n",
       "2                 NaN             NaN        Mollet del Valles    1005431   \n",
       "3                 NaN             NaN  Villanueva de la Canada    9049240   \n",
       "4                 NaN             NaN                 A Coruna    1005479   \n",
       "...               ...             ...                      ...        ...   \n",
       "8057              NaN             NaN    Castellon de la Plana    1005539   \n",
       "8058              NaN             NaN                  Seville    1005421   \n",
       "8059              NaN             NaN        Torrejon de Ardoz    1005496   \n",
       "8060              NaN             NaN                 Pamplona    1005503   \n",
       "8061  0 days 00:04:05             NaN                    Palma    1005517   \n",
       "\n",
       "                   region  regionId sessions  \n",
       "0               Catalonia     20278      2.0  \n",
       "1        Balearic Islands     21387      6.0  \n",
       "2               Catalonia     20278      2.0  \n",
       "3                  Madrid   9047045      1.0  \n",
       "4                 Galicia     20280      1.0  \n",
       "...                   ...       ...      ...  \n",
       "8057  Valencian Community     21388      1.0  \n",
       "8058            Andalusia     20269      2.0  \n",
       "8059               Madrid   9047045      1.0  \n",
       "8060              Navarre   9047051      1.0  \n",
       "8061     Balearic Islands     20287      3.0  \n",
       "\n",
       "[8062 rows x 106 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take out regions that are not from Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.sort_values(by = 'Date', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region\"].replace(' ', '_', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['region'].isin([\"Ile-de-France\",\"(not_set)\",\"Occitanie\",\"England\",\"Bogota\",\"Bavaria\",\"North_Rhine-Westphalia\",\"Porto_District\",\"Santiago_Metropolitan_Region\",\"Morelos\",\"Melilla\",\"Scotland\",\"Andorra_la_Vella\",\"Zulia\",\"Prague\",\"Lombardy\",\"Hessen\",\"New_York\",\"Capital_District\",\"North_Holland\",\"Occitania\",\"Azuay\",\"Cartago_Province\",\"Utrecht\",\"New_Hampshire\",\"Pays_de_la_Loire\",\"Georgia\",\"Santa_Fe_Province\",\"Buenos_Aires\",\"Rio_Grande\",\"Vienna\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[ 'categorySlug', 'region', 'RC', 'Comercio', 'sale']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropna columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(df, varlist):\n",
    "    for var in varlist:\n",
    "        df_slice = pd.get_dummies(df[var])\n",
    "        df = pd.concat([df.drop(var, axis =1), df_slice], axis =1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\", \"region\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\",\"region\"]\n",
    "X = df3.drop(columns='sale')\n",
    "X = get_dummies(X, categorical_list)\n",
    "y = df3['sale']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6456\n",
       "1     833\n",
       "Name: sale, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['sale'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4502\n",
       "1    2701\n",
       "Name: sale, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN \n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "oversamp_undersamp = SMOTETomek(sampling_strategy=0.6) #default sampling strategy\n",
    "X_train_b, y_train_b = oversamp_undersamp.fit_sample(X_train, y_train)\n",
    "X_train_b.shape, y_train_b.shape\n",
    "y_train_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81572930955647"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_b, np.ravel(y_train_b)).score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  4.4min\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Álvaro\\anaconda3.1\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Álvaro\\anaconda3.1\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Álvaro\\anaconda3.1\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Álvaro\\anaconda3.1\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Álvaro\\anaconda3.1\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Álvaro\\anaconda3.1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _fit_and_score\n    print(\"[CV] %s %s\" % (msg, (64 - len(msg)) * '.'))\nOSError: [Errno 22] Invalid argument\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-99787442c485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1529\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.1\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "rf_random.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest classifier best paramas')\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(n_estimators = 1600, min_samples_split = 10,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt', max_depth = None,\n",
    "                                    bootstrap = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = rf_optimal.predict(X_train_b)\n",
    "predictions_test = rf_optimal.predict(X_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(\"accuracy score on test:\", accuracy_score(y_test, predictions_test))\n",
    "print(\"accuracy on train:\", accuracy_score(y_train_b, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = pd.DatetimeIndex(df['Date']).month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include month as a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df[[ \"Month\",'categorySlug', 'region', 'RC', 'Comercio', 'sale']]\n",
    "df4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\",\"region\",\"Month\"]\n",
    "X = df4.drop(columns='sale')\n",
    "X = get_dummies(X, categorical_list)\n",
    "y = df4['sale']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['sale'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN \n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "oversamp_undersamp = SMOTETomek(sampling_strategy=0.6) #default sampling strategy\n",
    "X_train_b, y_train_b = oversamp_undersamp.fit_sample(X_train, y_train)\n",
    "X_train_b.shape, y_train_b.shape\n",
    "y_train_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_b, np.ravel(y_train_b)).score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest classifier best paramas')\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(n_estimators = 1800, min_samples_split = 10,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt', max_depth = 30,\n",
    "                                    bootstrap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month added\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = rf_optimal.predict(X_train_b)\n",
    "predictions_test = rf_optimal.predict(X_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(\"accuracy score on test:\", accuracy_score(y_test, predictions_test))\n",
    "print(\"accuracy on train:\", accuracy_score(y_train_b, predictions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include source as a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df[['categorySlug', 'region', 'RC', 'Comercio', 'sale',\"source\",\"Month\"]]\n",
    "\n",
    "df5=df5.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\",\"region\",\"source\",\"Month\"]\n",
    "X = df5.drop(columns='sale')\n",
    "X = get_dummies(X, categorical_list)\n",
    "y = df5['sale']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df5.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversamp_undersamp = SMOTETomek(sampling_strategy=0.6) #default sampling strategy\n",
    "X_train_b, y_train_b = oversamp_undersamp.fit_sample(X_train, y_train)\n",
    "X_train_b.shape, y_train_b.shape\n",
    "y_train_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_b, np.ravel(y_train_b)).score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest classifier best paramas')\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(n_estimators = 1800, min_samples_split = 10,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt', max_depth = 30,\n",
    "                                    bootstrap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month added\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = rf_optimal.predict(X_train_b)\n",
    "predictions_test = rf_optimal.predict(X_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(\"accuracy score on test:\", accuracy_score(y_test, predictions_test))\n",
    "print(\"accuracy on train:\", accuracy_score(y_train_b, predictions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include sessions as a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df[['categorySlug', 'region', 'RC', 'Comercio', 'sale',\"source\",\"Month\",\"sessions\"]]\n",
    "\n",
    "df6=df6.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\",\"region\",\"source\",\"Month\"]\n",
    "X = df6.drop(columns='sale')\n",
    "X = get_dummies(X, categorical_list)\n",
    "y = df6['sale']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversamp_undersamp = SMOTETomek(sampling_strategy=0.6) #default sampling strategy\n",
    "X_train_b, y_train_b = oversamp_undersamp.fit_sample(X_train, y_train)\n",
    "X_train_b.shape, y_train_b.shape\n",
    "y_train_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_b, np.ravel(y_train_b)).score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest classifier best paramas')\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(n_estimators = 1800, min_samples_split = 10,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt', max_depth = 30,\n",
    "                                    bootstrap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month added\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = rf_optimal.predict(X_train_b)\n",
    "predictions_test = rf_optimal.predict(X_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(\"accuracy score on test:\", accuracy_score(y_test, predictions_test))\n",
    "print(\"accuracy on train:\", accuracy_score(y_train_b, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We include weekday a as variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WEEKDAY'] = pd.to_datetime(df['Date']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df[['categorySlug', 'region', 'RC', 'Comercio', 'sale',\"source\",\"Month\",\"sessions\",\"WEEKDAY\"]]\n",
    "\n",
    "df7=df7.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\",\"region\",\"source\",\"Month\"]\n",
    "X = df7.drop(columns='sale')\n",
    "X = get_dummies(X, categorical_list)\n",
    "y = df7['sale']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversamp_undersamp = SMOTETomek(sampling_strategy=0.6) #default sampling strategy\n",
    "X_train_b, y_train_b = oversamp_undersamp.fit_sample(X_train, y_train)\n",
    "X_train_b.shape, y_train_b.shape\n",
    "y_train_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_b, np.ravel(y_train_b)).score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest classifier best paramas')\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(n_estimators = 1800, min_samples_split = 10,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt', max_depth = 30,\n",
    "                                    bootstrap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month added\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = rf_optimal.predict(X_train_b)\n",
    "predictions_test = rf_optimal.predict(X_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(\"accuracy score on test:\", accuracy_score(y_test, predictions_test))\n",
    "print(\"accuracy on train:\", accuracy_score(y_train_b, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "\n",
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comercio leads prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df[['categorySlug', 'region','Comercio', 'sale',\"source\",\"sessions\",\"quote\"]]\n",
    "\n",
    "df8=df8.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\",\"region\",\"source\"]\n",
    "X = df8.drop(columns='sale')\n",
    "X = get_dummies(X, categorical_list)\n",
    "y = df8['sale']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversamp_undersamp = SMOTETomek(sampling_strategy=0.6) #default sampling strategy\n",
    "X_train_b, y_train_b = oversamp_undersamp.fit_sample(X_train, y_train)\n",
    "X_train_b.shape, y_train_b.shape\n",
    "y_train_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_b, np.ravel(y_train_b)).score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest classifier best paramas')\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(n_estimators = 1800, min_samples_split = 10,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt', max_depth = 30,\n",
    "                                    bootstrap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Month added\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = rf_optimal.predict(X_train_b)\n",
    "predictions_test = rf_optimal.predict(X_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(\"accuracy score on test:\", accuracy_score(y_test, predictions_test))\n",
    "print(\"accuracy on train:\", accuracy_score(y_train_b, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "\n",
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_imp_rfpimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df[[ 'categorySlug', 'region', 'RC', 'Comercio', 'sale',\"source\",\"session_count_email\",\"session_count_userId\",\"quote\",\"sessions\"]]\n",
    "df9=df9.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list = [\"categorySlug\",\"region\",\"source\",\"Month\"]\n",
    "X = df9.drop(columns='sale')\n",
    "X = get_dummies(X, categorical_list)\n",
    "y = df9['sale']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversamp_undersamp = SMOTETomek(sampling_strategy=0.6) #default sampling strategy\n",
    "X_train_b, y_train_b = oversamp_undersamp.fit_sample(X_train, y_train)\n",
    "X_train_b.shape, y_train_b.shape\n",
    "y_train_b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_b, np.ravel(y_train_b)).score(X_test, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest classifier best paramas')\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(n_estimators = 600, min_samples_split = 10,\n",
    "                                    min_samples_leaf = 1, max_features = 'sqrt', max_depth = 40,\n",
    "                                    bootstrap = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = rf_optimal.predict(X_train_b)\n",
    "predictions_test = rf_optimal.predict(X_test)\n",
    "print(classification_report(y_test, predictions_test))\n",
    "print(\"accuracy score on test:\", accuracy_score(y_test, predictions_test))\n",
    "print(\"accuracy on train:\", accuracy_score(y_train_b, predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit depth of tree to 3 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "graph.write_png('small_tree.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
